
import { useState, useCallback, useRef } from 'react';
import { supabase } from '@/integrations/supabase/client';
import { useToast } from '@/hooks/use-toast';

interface UseElevenLabsTTSOptions {
  voiceId?: string;
  modelId?: string;
}

interface TTSCache {
  [key: string]: string; // hash du texte -> base64 audio
}

export const useElevenLabsTTS = (options: UseElevenLabsTTSOptions = {}) => {
  const [isLoading, setIsLoading] = useState(false);
  const [isPlaying, setIsPlaying] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [progress, setProgress] = useState(0);
  const [generationProgress, setGenerationProgress] = useState<string>('');
  
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const cacheRef = useRef<TTSCache>({});
  const { toast } = useToast();

  const {
    voiceId = '9BWtsMINqrJLrRacOk9x', // Aria par d√©faut
    modelId = 'eleven_multilingual_v2'
  } = options;

  // G√©n√®re une cl√© de cache bas√©e sur le texte et les param√®tres
  const getCacheKey = useCallback((text: string) => {
    const normalizedText = text.trim().toLowerCase();
    return `${voiceId}-${modelId}-${btoa(normalizedText).substring(0, 20)}`;
  }, [voiceId, modelId]);

  const stopAudio = useCallback(() => {
    if (audioRef.current) {
      audioRef.current.pause();
      audioRef.current.currentTime = 0;
      setIsPlaying(false);
      setProgress(0);
    }
  }, []);

  const clearCache = useCallback(() => {
    cacheRef.current = {};
    console.log('üóëÔ∏è Cache TTS vid√©');
    toast({
      title: "Cache vid√©",
      description: "Le cache des audios g√©n√©r√©s a √©t√© effac√©",
    });
  }, [toast]);

  const generateAndPlaySpeech = useCallback(async (text: string, showProgressToast: boolean = true) => {
    if (!text.trim()) {
      toast({
        title: "Erreur",
        description: "Le texte ne peut pas √™tre vide",
        variant: "destructive",
      });
      return;
    }

    // Si d√©j√† en train de jouer, arr√™ter
    if (isPlaying) {
      stopAudio();
      return;
    }

    const cacheKey = getCacheKey(text);
    
    // V√©rifier le cache d'abord
    if (cacheRef.current[cacheKey]) {
      console.log('üì¶ Audio trouv√© dans le cache');
      try {
        const audioBlob = new Blob(
          [Uint8Array.from(atob(cacheRef.current[cacheKey]), c => c.charCodeAt(0))],
          { type: 'audio/mpeg' }
        );
        const audioUrl = URL.createObjectURL(audioBlob);
        const audio = new Audio(audioUrl);
        audioRef.current = audio;
        
        audio.onplay = () => setIsPlaying(true);
        audio.onended = () => {
          setIsPlaying(false);
          setProgress(0);
          URL.revokeObjectURL(audioUrl);
        };
        audio.ontimeupdate = () => {
          if (audio.duration) {
            setProgress((audio.currentTime / audio.duration) * 100);
          }
        };
        
        await audio.play();
        
        if (showProgressToast) {
          toast({
            title: "Lecture depuis le cache",
            description: "Audio r√©cup√©r√© du cache local",
          });
        }
        return;
      } catch (error) {
        console.error('‚ùå Erreur lecture cache:', error);
        delete cacheRef.current[cacheKey];
      }
    }

    setIsLoading(true);
    setError(null);
    setGenerationProgress('Connexion √† ElevenLabs...');

    try {
      console.log('üéôÔ∏è D√©but g√©n√©ration ElevenLabs...', { 
        textLength: text.length, 
        voiceId, 
        modelId 
      });

      if (showProgressToast) {
        toast({
          title: "G√©n√©ration en cours",
          description: "Cr√©ation de l'audio avec ElevenLabs...",
        });
      }

      setGenerationProgress('Envoi du texte...');
      
      const { data, error } = await supabase.functions.invoke('elevenlabs-tts', {
        body: { 
          text,
          voiceId,
          modelId 
        }
      });

      console.log('üì° R√©ponse re√ßue:', { data, error });

      if (error) {
        console.error('‚ùå Erreur Supabase fonction:', error);
        throw new Error(`Erreur de connexion: ${error.message}`);
      }

      if (!data?.success || !data?.audioContent) {
        console.error('‚ùå R√©ponse invalide:', data);
        throw new Error(data?.error || 'R√©ponse invalide du service de synth√®se vocale');
      }

      // Mettre en cache l'audio g√©n√©r√©
      cacheRef.current[cacheKey] = data.audioContent;
      console.log('üíæ Audio mis en cache');

      setGenerationProgress('Pr√©paration de la lecture...');

      // Cr√©er l'URL audio √† partir du base64
      console.log('üéµ Cr√©ation de l\'audio blob...');
      const audioBlob = new Blob(
        [Uint8Array.from(atob(data.audioContent), c => c.charCodeAt(0))],
        { type: 'audio/mpeg' }
      );
      const audioUrl = URL.createObjectURL(audioBlob);

      // Cr√©er et configurer l'√©l√©ment audio
      const audio = new Audio(audioUrl);
      audioRef.current = audio;

      // Gestionnaires d'√©v√©nements audio
      audio.onloadstart = () => {
        console.log('üîÑ Chargement audio d√©marr√©');
        setGenerationProgress('Chargement audio...');
      };
      
      audio.oncanplay = () => {
        console.log('‚úÖ Audio pr√™t √† jouer');
        setIsLoading(false);
        setGenerationProgress('');
      };
      
      audio.onplay = () => {
        console.log('‚ñ∂Ô∏è Lecture audio d√©marr√©e');
        setIsPlaying(true);
      };
      
      audio.ontimeupdate = () => {
        if (audio.duration) {
          setProgress((audio.currentTime / audio.duration) * 100);
        }
      };
      
      audio.onended = () => {
        console.log('‚èπÔ∏è Lecture audio termin√©e');
        setIsPlaying(false);
        setProgress(0);
        URL.revokeObjectURL(audioUrl);
      };
      
      audio.onerror = (e) => {
        console.error('üí• Erreur lecture audio:', e);
        setIsPlaying(false);
        setProgress(0);
        setError('Erreur lors de la lecture audio');
        URL.revokeObjectURL(audioUrl);
        toast({
          title: "Erreur de lecture",
          description: "Impossible de lire l'audio g√©n√©r√©",
          variant: "destructive",
        });
      };

      // Lancer la lecture
      await audio.play();

      if (showProgressToast) {
        toast({
          title: "Lecture d√©marr√©e",
          description: data.segments 
            ? `Audio g√©n√©r√© (${data.processedTextLength}/${data.originalTextLength} caract√®res)`
            : "Audio g√©n√©r√© avec succ√®s",
        });
      }

    } catch (error: any) {
      console.error('üí• Erreur synth√®se vocale:', error);
      const errorMessage = error.message || 'Erreur lors de la g√©n√©ration de la voix';
      setError(errorMessage);
      
      // Messages d'erreur sp√©cifiques
      let userMessage = "Impossible de g√©n√©rer l'audio";
      if (errorMessage.includes('Cl√© API') || errorMessage.includes('invalide')) {
        userMessage = "Configuration ElevenLabs incorrecte. V√©rifiez votre cl√© API.";
      } else if (errorMessage.includes('quota') || errorMessage.includes('limite')) {
        userMessage = "Limite ElevenLabs atteinte. V√©rifiez votre plan ou attendez.";
      } else if (errorMessage.includes('Timeout') || errorMessage.includes('timeout')) {
        userMessage = "La g√©n√©ration a pris trop de temps. Essayez un texte plus court.";
      } else if (errorMessage.includes('connexion')) {
        userMessage = "Probl√®me de connexion. V√©rifiez votre r√©seau.";
      }
      
      toast({
        title: "Erreur de synth√®se vocale",
        description: userMessage,
        variant: "destructive",
      });
    } finally {
      setIsLoading(false);
      setGenerationProgress('');
    }
  }, [voiceId, modelId, isPlaying, stopAudio, toast, getCacheKey]);

  return {
    generateAndPlaySpeech,
    stopAudio,
    clearCache,
    isLoading,
    isPlaying,
    error,
    progress,
    generationProgress,
    cacheSize: Object.keys(cacheRef.current).length
  };
};
